{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick notes about this task \n",
    "- There might be an easier way to run the models using ngrams provided by openalex, but I was stuck on it for too long so I decided to revert the abstracts indices into abstracts and use them for classification.\n",
    "- I assumed that all the articles from american economic review are economics related and all the american political science review articles are political science related. Some articles might be related to both but I did not make the distinction here. \n",
    "- I manually checked some of the abstracts and one actually said \"no abstract is available for this article ...\", I didn't remove it and kept it in the model which means it probably served as noice in the data but this was not very common.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages for making database\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(issn, per_page = 50, num_page = 1):\n",
    "    '''\n",
    "    Function that takes issn, results per page, and how many pages as parameter for function.\n",
    "\n",
    "    Parameters:\n",
    "        issn (str): The ISSN (International Standard Serial Number) of the academic journal.\n",
    "        results_per_page (int): The number of results (articles) per page to be returned.\n",
    "        num_pages (int): The number of pages of results to retrieve.\n",
    "\n",
    "    Returns openalex api query with desired filters\n",
    "    '''\n",
    "    url = f\"https://api.openalex.org/works?&sort=publication_year:desc&per-page={per_page}&page={num_page}&filter=locations.source.issn:{issn}&select=id,display_name,doi,publication_year,abstract_inverted_index\"\n",
    "    return url\n",
    "\n",
    "#function to check the number of None for abstract \n",
    "def check(api_response):\n",
    "    '''\n",
    "    Function that takes the API response as a parameter and checks the number of None in the abstract inverted index.\n",
    "\n",
    "    Parameters:\n",
    "        api_response (requests.Response): The API response object obtained from the OpenAlex API.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of occurrences of None in the abstract inverted index.\n",
    "    '''\n",
    "    check = []\n",
    "    for i, result in enumerate(api_response.json()[\"results\"]):\n",
    "        check.append(result[\"abstract_inverted_index\"])\n",
    "    return(sum([x is None for x in check]))\n",
    "\n",
    "def create_df(api_response, label_num):\n",
    "    '''\n",
    "    Function that takes the API response and a label number as input and returns a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        api_response (requests.Response): The API response object obtained from the OpenAlex API.\n",
    "        label_num (int): The label number to assign to the articles in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing information about the articles.\n",
    "\n",
    "    '''\n",
    "    title = []\n",
    "    abstract = []\n",
    "    year=[]\n",
    "    id = []\n",
    "    labels = [label_num]*100\n",
    "    for i, result in enumerate(api_response.json()[\"results\"]):\n",
    "        if result[\"abstract_inverted_index\"] is None:\n",
    "            continue \n",
    "        else:   \n",
    "            title.append(result[\"display_name\"])\n",
    "            year.append(result[\"publication_year\"])\n",
    "            abstract.append(result[\"abstract_inverted_index\"])\n",
    "            id.append(result[\"id\"])\n",
    "    \n",
    "    return pd.DataFrame({\"Title\":title, \"id\":id, \"publication_year\": year, \"abstract_index\":abstract, \"label\":labels})\n",
    "\n",
    "def convert_indices_to_abstract(abstractInvertedIndex):\n",
    "    '''\n",
    "    Function that takes an abstract inverted index as input and reconstructs the original abstract.\n",
    "\n",
    "    Parameters:\n",
    "        abstractInvertedIndex (dict): The abstract inverted index where keys are words and values are lists of indices.\n",
    "\n",
    "    Returns:\n",
    "        str: The reconstructed abstract.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Create the word_index list and sort it by index\n",
    "    word_index = []\n",
    "    for k, v in abstractInvertedIndex.items():\n",
    "        for index in v:\n",
    "            word_index.append([k, index])\n",
    "    word_index = sorted(word_index, key=lambda x: x[1])\n",
    "\n",
    "    #Join the words from word_index list with spaces to form the abstract\n",
    "    abstract = []\n",
    "    prev_index = None\n",
    "    for word, index in word_index:\n",
    "        if index == prev_index:\n",
    "            abstract[-1] += ' ' + word  # Append the word to the previous word\n",
    "        else:\n",
    "            abstract.append(word)  # Add a new word to the abstract\n",
    "        prev_index = index\n",
    "\n",
    "    return ' '.join(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#American Economic Review \n",
    "aer_issn = \"1944-7981\"\n",
    "aer_query = create_query(aer_issn, 116, 1)\n",
    "aer_response = requests.get(aer_query)\n",
    "check(aer_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "aer_df = create_df(aer_response, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#American political science review \n",
    "apsr_issn = \"1537-5943\"\n",
    "apsr_query = create_query(apsr_issn, 100, 1)\n",
    "apsr_response = requests.get(apsr_query)\n",
    "check(apsr_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "apsr_df = create_df(apsr_response, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>abstract_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Embedding Regression: Models for Context-Speci...</td>\n",
       "      <td>https://openalex.org/W4317434765</td>\n",
       "      <td>2023</td>\n",
       "      <td>{'Social': [0], 'scientists': [1], 'commonly':...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Divided We Unite: The Nature of Partyism and t...</td>\n",
       "      <td>https://openalex.org/W4361275997</td>\n",
       "      <td>2023</td>\n",
       "      <td>{'Highlighting': [0], 'the': [1, 52, 55, 75, 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Slavery in the Making of States and Int...</td>\n",
       "      <td>https://openalex.org/W4379986437</td>\n",
       "      <td>2023</td>\n",
       "      <td>{'Despite': [0], 'having': [1], 'key': [2], 'i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modeling Spatial Heterogeneity and Historical ...</td>\n",
       "      <td>https://openalex.org/W4322769899</td>\n",
       "      <td>2023</td>\n",
       "      <td>{'A': [0], 'wealth': [1], 'of': [2, 55], 'rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which Markets, Whose Rationality? Markets as P...</td>\n",
       "      <td>https://openalex.org/W4316466446</td>\n",
       "      <td>2023</td>\n",
       "      <td>{'This': [0, 77], 'article': [1, 96], 'explica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Embedding Regression: Models for Context-Speci...   \n",
       "1  Divided We Unite: The Nature of Partyism and t...   \n",
       "2  Global Slavery in the Making of States and Int...   \n",
       "3  Modeling Spatial Heterogeneity and Historical ...   \n",
       "4  Which Markets, Whose Rationality? Markets as P...   \n",
       "\n",
       "                                 id  publication_year  \\\n",
       "0  https://openalex.org/W4317434765              2023   \n",
       "1  https://openalex.org/W4361275997              2023   \n",
       "2  https://openalex.org/W4379986437              2023   \n",
       "3  https://openalex.org/W4322769899              2023   \n",
       "4  https://openalex.org/W4316466446              2023   \n",
       "\n",
       "                                      abstract_index  label  \n",
       "0  {'Social': [0], 'scientists': [1], 'commonly':...      1  \n",
       "1  {'Highlighting': [0], 'the': [1, 52, 55, 75, 8...      1  \n",
       "2  {'Despite': [0], 'having': [1], 'key': [2], 'i...      1  \n",
       "3  {'A': [0], 'wealth': [1], 'of': [2, 55], 'rece...      1  \n",
       "4  {'This': [0, 77], 'article': [1, 96], 'explica...      1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.concat([apsr_df,aer_df], axis = 0)\n",
    "total_df.index = range(200)\n",
    "print(len(total_df))\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_abstract = []\n",
    "for i in total_df[\"abstract_index\"]:\n",
    "    full_abstract = convert_indices_to_abstract(i)\n",
    "    new_abstract.append(full_abstract)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social scientists commonly seek to make statem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Highlighting the strength of “partyism” in man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despite having key implications for fundamenta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A wealth of recent research in comparative pol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This article explicates and critiques an under...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  Label\n",
       "0  Social scientists commonly seek to make statem...      1\n",
       "1  Highlighting the strength of “partyism” in man...      1\n",
       "2  Despite having key implications for fundamenta...      1\n",
       "3  A wealth of recent research in comparative pol...      1\n",
       "4  This article explicates and critiques an under...      1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'abstract':new_abstract, 'Label': total_df['label']})\n",
    "print(len(new_df))\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Models \n",
    "### I ran 4 models each with 3 difference combinations of ngrams, 1 with unigrams only, 1 with unigrams and bigrams, 1 with unigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Mean Accuracy = 0.9300, Std Dev = 0.0430\n",
      "Logistic Regression: Mean Accuracy = 0.9700, Std Dev = 0.0100\n",
      "Random Forest: Mean Accuracy = 0.9850, Std Dev = 0.0200\n",
      "Support Vector Machine: Mean Accuracy = 0.9000, Std Dev = 0.0632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = new_df['abstract']\n",
    "y = new_df['Label']\n",
    "\n",
    "# Split data into training and testing sets for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2022, stratify=y)\n",
    "\n",
    "# UNIGRAM \n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=2022)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=2022)),\n",
    "    ('Support Vector Machine', SVC(random_state=2022))\n",
    "]\n",
    "\n",
    "# Pipelines\n",
    "pipelines = [\n",
    "    (name, Pipeline([\n",
    "        ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),\n",
    "        ('model', model)\n",
    "    ])) for name, model in models\n",
    "]\n",
    "\n",
    "for name, model in pipelines:\n",
    "    # Perform cross-validation with 5 folds\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f}, Std Dev = {scores.std():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Mean Accuracy = 0.9350, Std Dev = 0.0436\n",
      "Logistic Regression: Mean Accuracy = 0.9600, Std Dev = 0.0255\n",
      "Random Forest: Mean Accuracy = 0.9650, Std Dev = 0.0374\n",
      "Support Vector Machine: Mean Accuracy = 0.7550, Std Dev = 0.0458\n"
     ]
    }
   ],
   "source": [
    "# UNIGRAM, BIGRAM\n",
    "# Pipelines\n",
    "pipelines = [\n",
    "    (name, Pipeline([\n",
    "        ('vectorizer_bow', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('model', model)\n",
    "    ])) for name, model in models\n",
    "]\n",
    "\n",
    "for name, model in pipelines:\n",
    "    # Perform cross-validation with 5 folds\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f}, Std Dev = {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: Mean Accuracy = 0.9350, Std Dev = 0.0436\n",
      "Logistic Regression: Mean Accuracy = 0.9500, Std Dev = 0.0316\n",
      "Random Forest: Mean Accuracy = 0.9150, Std Dev = 0.0464\n",
      "Support Vector Machine: Mean Accuracy = 0.6100, Std Dev = 0.0583\n"
     ]
    }
   ],
   "source": [
    "# UNIGRAM, TRIGRAM\n",
    "# Pipelines\n",
    "pipelines = [\n",
    "    (name, Pipeline([\n",
    "        ('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
    "        ('model', model)\n",
    "    ])) for name, model in models\n",
    "]\n",
    "\n",
    "for name, model in pipelines:\n",
    "    # Perform cross-validation with 5 folds\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"{name}: Mean Accuracy = {scores.mean():.4f}, Std Dev = {scores.std():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
